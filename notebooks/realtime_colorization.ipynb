{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.color import lab2rgb, rgb2lab\n",
    "\n",
    "from dataset.user_guided_dataset import UserGuidedVideoDataset\n",
    "from dataset.util import unnormalize_lab\n",
    "from model.user_guided_unet import UserGuidedUNet\n",
    "from model.zhang_model import SIGGRAPHGenerator\n",
    "from test_utils import predict_user_guided\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../datasets/bw-frames/test/00078.png'\n",
    "# model_path = '../checkpoint/siggraph_caffemodel/latest_net_G.pth'\n",
    "model_path = '../checkpoint/lr1e-06_2020-06-16-15-07-15_userguide_qss_lower_lr/epoch0_iter14999.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both 3D tensors\n",
    "L_channel, ab_channels, _, _, _ = UserGuidedVideoDataset('', [image_path], random_crop=None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = torch.load(model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Zhang model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SIGGRAPHGenerator(4, 2)\n",
    "model.load_state_dict(saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create UserGuidedUNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(UserGuidedUNet())\n",
    "model.load_state_dict(saved_model['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create default inputs for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# All 4D tensors, with first dim being batch size (1)\n",
    "input_L = L_channel.unsqueeze(0)\n",
    "input_ab = torch.zeros_like(ab_channels).unsqueeze(0)\n",
    "input_mask = torch.zeros_like(input_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = predict_user_guided(model, device, input_L, input_ab, input_mask, ab_multiplier=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grayscale_and_hints = unnormalize_lab(L_channel, torch.zeros((2, L_channel.shape[1], L_channel.shape[2])))\n",
    "grayscale_and_hints = grayscale_and_hints.permute((1, 2, 0))\n",
    "grayscale_and_hints = lab2rgb(grayscale_and_hints.detach().cpu().numpy())\n",
    "\n",
    "plt.figure(figsize = (9, 4))\n",
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "gs1.update(left=0, right=1, top=1, bottom=0, wspace=0, hspace=0)\n",
    "\n",
    "ax1 = plt.subplot(gs1[0])\n",
    "ax2 = plt.subplot(gs1[1])\n",
    "\n",
    "ax1.imshow(grayscale_and_hints)\n",
    "ax2.imshow(rgb)\n",
    "ax1.set_axis_off()\n",
    "ax2.set_axis_off()\n",
    "\n",
    "hint_xy = None\n",
    "hint_size = None\n",
    "hint_rgb = None\n",
    "hint_lab = None\n",
    "hint_text = ax1.text(0, 0, \"\", va=\"bottom\", ha=\"left\")\n",
    "\n",
    "candidate_ab_hint = None\n",
    "candidate_ab_mask = None\n",
    "\n",
    "def update_text_and_pred():\n",
    "    global candidate_ab_hint\n",
    "    global candidate_ab_mask\n",
    "    hint_text.set_text(f'Hint pos: {hint_xy}, size: {hint_size}, rgb: {hint_rgb}, lab: {hint_lab}')\n",
    "    \n",
    "    if hint_xy is not None and hint_size is not None and hint_rgb is not None:\n",
    "        candidate_ab_hint = input_ab.clone()\n",
    "        candidate_ab_mask = input_mask.clone()\n",
    "\n",
    "        x, y = hint_xy\n",
    "        candidate_ab_mask[0, 0, y : y+hint_size, x : x+hint_size] = 1\n",
    "        # Update hint and normalize it\n",
    "        candidate_ab_hint[0, :, y : y+hint_size, x : x+hint_size] = \\\n",
    "            torch.tensor(hint_lab[0, 0, 1:]).unsqueeze(1).unsqueeze(1) / 110\n",
    "        \n",
    "        grayscale_and_hints = unnormalize_lab(L_channel, candidate_ab_hint.squeeze())\n",
    "        grayscale_and_hints = grayscale_and_hints.permute((1, 2, 0))\n",
    "        grayscale_and_hints = lab2rgb(grayscale_and_hints.detach().cpu().numpy())\n",
    "        ax1.imshow(grayscale_and_hints)\n",
    "        \n",
    "        rgb = predict_user_guided(model, device, input_L, candidate_ab_hint, candidate_ab_mask,\n",
    "                                 ab_multiplier=0.3)\n",
    "        ax2.imshow(rgb)\n",
    "        \n",
    "\n",
    "def update_hint_pos(event):\n",
    "    global hint_xy\n",
    "    x = int(event.xdata)\n",
    "    y = int(event.ydata)\n",
    "    hint_xy = [x, y]\n",
    "    update_text_and_pred()\n",
    "    \n",
    "def update_hint_size(change):\n",
    "    global hint_size\n",
    "    hint_size = int(change['new'])\n",
    "    update_text_and_pred()\n",
    "    \n",
    "def update_hint_color(change):\n",
    "    global hint_rgb\n",
    "    global hint_lab\n",
    "    hex_value = change['new'].lstrip('#')\n",
    "    hint_rgb = np.array([[[int(hex_value[i : i+2], 16) for i in (0, 2, 4)]]]).astype('float')\n",
    "    hint_lab = rgb2lab(hint_rgb / 255)\n",
    "    print(hint_lab)\n",
    "    update_text_and_pred()\n",
    "\n",
    "ka = ax1.figure.canvas.mpl_connect('button_press_event', update_hint_pos)\n",
    "\n",
    "color_picker = widgets.ColorPicker(\n",
    "    concise=False,\n",
    "    description='Pick a color',\n",
    "    value='blue',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "slider = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Test:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "slider.observe(update_hint_size, names='value')\n",
    "color_picker.observe(update_hint_color, names='value')\n",
    "\n",
    "display(color_picker)\n",
    "display(slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commit selected value to hint and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_ab = candidate_ab_hint.clone()\n",
    "input_mask = candidate_ab_mask.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}